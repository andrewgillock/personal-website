{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2023-03-12T21:03:20-05:00"
    },
    {
      "path": "index.html",
      "title": "Andrew Gillock",
      "author": [],
      "contents": "\n\n          \n          \n          Home\n          \n          \n          \n          \n          Posts\n           \n          ▾\n          \n          \n          MNIST Classification\n          \n          \n          ☰\n          \n          \n      \n        \n          \n            \n              \n            \n              Andrew Gillock\n            \n            \n              \n                \n                    \n                      \n                        LinkedIn\n                      \n                    \n                  \n                                    \n                    \n                      \n                        Twitter\n                      \n                    \n                  \n                                    \n                    \n                      \n                         GitHub\n                      \n                    \n                  \n                                    \n                    \n                      \n                        Email\n                      \n                    \n                  \n                                  \n            \n          \n        \n        \n        \n          \n            \n            About Me\n            Frank Hermosillo studies neural networks and their\n            applications at Google Brain. His research focuses on\n            differentiable network pruning approximation and\n            decentralized gradient inversion mechanics. He frequently\n            collaborates with researchers who study machine learning,\n            computer vision, and cognitive science. His work has been\n            featured in WIRED, The Atlantic, Newsweek, and The New York\n            Times Magazine.\n            \n            \n            Education\n            Massachusetts Institute of Technology |\n            Cambridge, MA\n            Ph.D. in Computer Science | September 2009 - May 2014\n            The University of California, Berkeley |\n            Berkeley, CA\n            B.S. in Computer Science | September 2005 - May 2009\n            \n            \n            Experience\n            Google Brain | Principal Investigator |\n            January 2018 - Present\n            Netflix | Research Scientist | June 2014\n            - December 2017\n            \n          \n        \n      \n    \n\n    \n      \n        \n          \n            \n              \n            \n              Andrew Gillock\n            \n            \n              \n                \n                                    \n                    \n                      LinkedIn\n                    \n                  \n                                    \n                    \n                      Twitter\n                    \n                  \n                                    \n                    \n                       GitHub\n                    \n                  \n                                    \n                    \n                      Email\n                    \n                  \n                                  \n              \n            \n            \n              \n              About Me\n              Frank Hermosillo studies neural networks and their\n              applications at Google Brain. His research focuses on\n              differentiable network pruning approximation and\n              decentralized gradient inversion mechanics. He frequently\n              collaborates with researchers who study machine learning,\n              computer vision, and cognitive science. His work has been\n              featured in WIRED, The Atlantic, Newsweek, and The New\n              York Times Magazine.\n              \n              \n              Education\n              Massachusetts Institute of Technology\n              | Cambridge, MA\n              Ph.D. in Computer Science | September 2009 - May\n              2014\n              The University of California, Berkeley\n              | Berkeley, CA\n              B.S. in Computer Science | September 2005 - May\n              2009\n              \n              \n              Experience\n              Google Brain | Principal Investigator\n              | January 2018 - Present\n              Netflix | Research Scientist | June\n              2014 - December 2017\n              \n            \n        \n      \n    \n\n    \n    \n    ",
      "last_modified": "2023-03-12T21:03:23-05:00"
    },
    {
      "path": "mnist.html",
      "title": "Classifying the MNIST Dataset",
      "author": [
        {
          "name": "Andrew Gillock",
          "url": {}
        }
      ],
      "contents": "\nIntroduction\n\n\n\nThe Modified National Institute of Standards and Technology (MNIST) dataset is a large database composed of 70,000 handwritten digits. Each ‘image’ is a 28x28 dataframe containing single grayscale values in each element of the matrix. This database is frequently used to understand image classification machine learning models through pattern recognition. The goal of this project is to design a convolutional neural network that classifies the MNIST test dataset with 99% or greater accuracy.\n\nimport pandas\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nI will begin this exercise by downloading the MNIST dataset from the keras library. A few other housekeeping things must be accounted for, such as normalizing the gray-scale values prior to analysis and reshaping our training/testing data for the tensorflow model. Tensorflow requires us to include a third dimension for our images, but since we are dealing with gray-scale (instead of color) we can set this value to be 1. Finally, we obtain the shape of each image that will be ran through the model.\n\nmnist = tf.keras.datasets.mnist # load in data\n\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\n\nx_train, x_test = x_train / 255.0, x_test / 255.0 # normalize grayscale values\n\n# get lengths of train/test\nndata_train = x_train.shape[0] # = 60000\nndata_test = x_test.shape[0] # = 10000\n\n# tensorflow requires us to include 3rd dimension for color (1)\nx_train2 = x_train.reshape((ndata_train,28,28,1))\nx_test2 = x_test.reshape((ndata_test,28,28,1))\n\nxshape = x_train2.shape[1:4] # we only need the image dimensions for the model\n\nDesigning the Network Architecture\nConvolutional neural networks (CNNs) are often used in models that take images as input. They work by applying a set of filters to the image, which can be thought of as a small subset of the original photo. Similarity scores (the dot product of filter and that portion of the image) are computed between the filter and image as the filter is moved across different positions in the image. An example of a filter is seen below in Figure 1.\n\n\n\nFigure 1: Example of a small filter applied to each region of the original image\n\n\n\nThe application of filters results in significantly more data which can increase processing times for the network. In order to ‘fix’ this problem, we can introduce a max pooling layer, which functions similar to a filter. The max pool filter moves across the similarity score matrix, but rather than computing the dot product, the largest value within the filter is used to define that whole section of similarity. As a result, we decrease the number of input neurons required by the dense neural network and identify the general vicinity of corresponding filter-image similarities. The output of the max pool layer is passed into a dense neural network to complete the classification. The final output of the model is a vector of 10 probabilities, one for each digit 0-9. The index with the largest probability is the number predicted by the network. A visualization of this process can be seen below in Figure 2.\n\n\n\nFigure 2: Visualization of max pool layer following a convolutional layer\n\n\n\nUsing this information, I will now develop my own CNN with the goal of achieving 99% or greater classification accuracy on the MNIST test dataset. I began this process by fitting different combinations of convolution and max pool layers to the training set of 60,000 images. A validation split of 0.2 was used to prevent overfitting of the model. For the convolutional layers, I found that 2 layers of small filters, a max pool layer, another convolutional layer, and a final max pool layer present us with the largest validation accuracy. The first convolutional layer is composed of 20 5x5 filters and a ReLU activation. The second convolutional layer has 20 2x2 filters and a ReLU activation. The first max pool layer uses a pool size of 2x2 with a stride of 2 to prevent overlap. The final convolutional layer contains 50 2x2 filters and a ReLU activation. The final max pool layer once again uses a pool size of 2x2 and a stride of 2. The output of the final max pool layer is fed into multiple dense and dropout layers before outputting the final classification of the image. Once the model achieved greater than 99% validation accuracy, we retrained the same model using the entire training set. A summary of my model can be seen below. Additionally, Figure 3 displays a completed CNN similar to my own, which helps with a visualization of the model.\n\nNNmodel = tf.keras.models.Sequential()\nNNmodel.add(tf.keras.layers.Conv2D(filters = 20, kernel_size = (5,5), activation = tf.nn.relu, input_shape = xshape))\nNNmodel.add(tf.keras.layers.Conv2D(filters = 20, kernel_size = (2,2), activation = tf.nn.relu))\nNNmodel.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2))\nNNmodel.add(tf.keras.layers.Conv2D(filters = 50, kernel_size = (2,2), activation = tf.nn.relu))\nNNmodel.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = 2))\nNNmodel.add(tf.keras.layers.Flatten())\nNNmodel.add(tf.keras.layers.Dropout(rate = 0.4))\nNNmodel.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\nNNmodel.add(tf.keras.layers.Dropout(rate = 0.2))\nNNmodel.add(tf.keras.layers.Dense(64,activation=tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l1(0.0005)))\nNNmodel.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n\n\n\n\n\nNNmodel.summary()\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_3 (Conv2D)           (None, 24, 24, 20)        520       \n                                                                 \n conv2d_4 (Conv2D)           (None, 23, 23, 20)        1620      \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 11, 11, 20)       0         \n 2D)                                                             \n                                                                 \n conv2d_5 (Conv2D)           (None, 10, 10, 50)        4050      \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 5, 5, 50)         0         \n 2D)                                                             \n                                                                 \n flatten_1 (Flatten)         (None, 1250)              0         \n                                                                 \n dropout_2 (Dropout)         (None, 1250)              0         \n                                                                 \n dense_3 (Dense)             (None, 128)               160128    \n                                                                 \n dropout_3 (Dropout)         (None, 128)               0         \n                                                                 \n dense_4 (Dense)             (None, 64)                8256      \n                                                                 \n dense_5 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 175,224\nTrainable params: 175,224\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\n\nFigure 3: Visualization of a CNN used to classify an image\n\n\n\nModel Results\nNow that we have determined a network architecture, we can evaluate the model.\n\nNNmodel.evaluate(x_test2, y_test, verbose = 0)\n[0.04142482578754425, 0.9934999942779541]\n\nThe model correctly classifies 99.35% of images in the MNIST test set! Let’s determine which images were classified incorrectly and try to see why the model was wrong.\n\npredicted = NNmodel.predict(x_test, verbose = 0) # obtain vector of probabilities for each image\n\ndef get_guess(predicted):\n    '''this method takes all predicted probabilities and returns the predicted classification for each image'''\n    guesses = []\n    for i in predicted:\n        guess = i.argmax()\n        guesses.append(guess)\n    return guesses\n\nguesses = get_guess(predicted)\n\n# get indexes of correctly classified images\ncorrect = np.where(np.equal(guesses, y_test))\ncorrect = correct[0].tolist()\n\n# get indexes of misclassified images\nincorrect = np.where(np.not_equal(guesses, y_test))\nincorrect = incorrect[0].tolist()\n\nprint('Correct:', len(correct))\nCorrect: 9935\nprint('Incorrect:', len(incorrect))\nIncorrect: 65\n\nOut of the 10,000 images in the test set, the model correctly classifies 9,935 images and misclassifies 65 images. Despite achieving greater than 99% classification accuracy, I’m left questioning how to further improve this model.\nLet’s take a look at some of the images that are correctly/incorrectly classified to see the issues the model runs in to.\nExample 1\n\nPredicted: 4\nActual: 9\n\n\nExample 2\n\nPredicted: 1\nActual: 7\n\n\nExample 3\n\nPredicted: 6\nActual: 0\n\n\nIt appears that most of the misclassified numbers were poorly drawn or resemble other numbers based on their features. We can assume that our convolutional layers may pick up on patterns in these images that resemble patterns of other numbers. For example, a handwritten ‘6’ may be classified as a ‘0’ if the line above the enclosed area does not extend high enough. Additionally, we might see a ‘4’ get classified as a ‘9’ depending on the orientation of the image. When we examine correctly classified numbers, nearly all of these hand-drawn digits are clearly legible and distinguishable.\nGiven these observations, we can conclude that although the model may be improved, we will never achieve 100% classification accuracy on the test set. Since each digit is hand-drawn, there is too much variability between the neatness and structure in handwriting of the individuals used in the training and test set.\n\n\n\n",
      "last_modified": "2023-03-12T21:03:57-05:00"
    }
  ],
  "collections": []
}
